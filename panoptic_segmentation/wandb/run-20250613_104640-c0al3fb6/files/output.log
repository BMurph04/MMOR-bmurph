Frequency file exists. Using weights from frequency file
Using no loss weighting...
[32m[06/13 10:46:42 d2.engine.defaults]: [0mModel:
CTMinVIS(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): VideoMultiScaleMaskedTransformerDecoder_dvisPlus(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(100, 256)
      (query_embed): Embedding(100, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=125, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (reid_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion VideoSetCriterion
      matcher: Matcher VideoHungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 124
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
  (image_matcher): Matcher HungarianMatcher
      cost_class: 2.0
      cost_mask: 5.0
      cost_dice: 5.0
  (cl_plugin): CTCLPlugin()
)
[32m[06/13 10:46:42 fvcore.common.checkpoint]: [0m[Checkpointer] Loading from checkpoints/ctvis_r50_vspw.pth ...
Loading samples: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 27.24it/s]
[32m[06/13 10:46:44 d2.data.common]: [0mSerializing 72 elements to byte tensors and concatenating them all ...
[32m[06/13 10:46:45 d2.data.common]: [0mSerialized dataset takes 14.05 MiB
COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[32m[06/13 10:46:45 d2.evaluation.evaluator]: [0mStart inference on 72 batches
/home/connecteve/miniconda3/envs/mm-or/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525541990/work/aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
43
34
51
97
91
[32m[06/13 10:47:09 d2.evaluation.evaluator]: [0mInference done 1/72. Dataloading: 0.0119 s/iter. Inference: 16.9825 s/iter. Eval: 6.8536 s/iter. Total: 23.8489 s/iter. ETA=0:28:13
43
51
91
34
47
[32m[06/13 10:47:29 d2.evaluation.evaluator]: [0mInference done 2/72. Dataloading: 0.0519 s/iter. Inference: 15.3505 s/iter. Eval: 6.7809 s/iter. Total: 22.1839 s/iter. ETA=0:25:52
43
34
51
91
[32m[06/13 10:47:49 d2.evaluation.evaluator]: [0mInference done 3/72. Dataloading: 0.0657 s/iter. Inference: 14.7688 s/iter. Eval: 6.6979 s/iter. Total: 21.5330 s/iter. ETA=0:24:45
43
34
51
[32m[06/13 10:48:10 d2.evaluation.evaluator]: [0mInference done 4/72. Dataloading: 0.0770 s/iter. Inference: 14.5244 s/iter. Eval: 6.6960 s/iter. Total: 21.2980 s/iter. ETA=0:24:08
43
34
51
[32m[06/13 10:48:31 d2.evaluation.evaluator]: [0mInference done 5/72. Dataloading: 0.0746 s/iter. Inference: 14.4195 s/iter. Eval: 6.6786 s/iter. Total: 21.1731 s/iter. ETA=0:23:38
43
34
51
31
37
37
36
36
36
47
80
28
34
43
47
25
91
97
28
28
[32m[06/13 10:48:51 d2.evaluation.evaluator]: [0mInference done 7/72. Dataloading: 0.0657 s/iter. Inference: 6.9787 s/iter. Eval: 3.3838 s/iter. Total: 10.4283 s/iter. ETA=0:11:17
43
34
28
28
[32m[06/13 10:49:11 d2.evaluation.evaluator]: [0mInference done 8/72. Dataloading: 0.0912 s/iter. Inference: 8.9597 s/iter. Eval: 4.2764 s/iter. Total: 13.3274 s/iter. ETA=0:14:12
34
43
[32m[06/13 10:49:30 d2.evaluation.evaluator]: [0mInference done 9/72. Dataloading: 0.1044 s/iter. Inference: 9.9309 s/iter. Eval: 4.7014 s/iter. Total: 14.7369 s/iter. ETA=0:15:28
43
34
47
28
[32m[06/13 10:49:49 d2.evaluation.evaluator]: [0mInference done 10/72. Dataloading: 0.0998 s/iter. Inference: 10.5119 s/iter. Eval: 4.9802 s/iter. Total: 15.5921 s/iter. ETA=0:16:06
34
43
28
28
[32m[06/13 10:50:07 d2.evaluation.evaluator]: [0mInference done 11/72. Dataloading: 0.0952 s/iter. Inference: 10.8313 s/iter. Eval: 5.1082 s/iter. Total: 16.0350 s/iter. ETA=0:16:18
43
34
37
87
72
32
47
41
28
43
51
34
85
37
25
72
91
[32m[06/13 10:50:26 d2.evaluation.evaluator]: [0mInference done 13/72. Dataloading: 0.0820 s/iter. Inference: 9.7391 s/iter. Eval: 4.5994 s/iter. Total: 14.4208 s/iter. ETA=0:14:10
43
34
31
[32m[06/13 10:50:44 d2.evaluation.evaluator]: [0mInference done 14/72. Dataloading: 0.0829 s/iter. Inference: 10.0063 s/iter. Eval: 4.7327 s/iter. Total: 14.8222 s/iter. ETA=0:14:19
43
34
25
51
[32m[06/13 10:51:02 d2.evaluation.evaluator]: [0mInference done 15/72. Dataloading: 0.0853 s/iter. Inference: 10.2112 s/iter. Eval: 4.8330 s/iter. Total: 15.1298 s/iter. ETA=0:14:22
34
43
51
[32m[06/13 10:51:20 d2.evaluation.evaluator]: [0mInference done 16/72. Dataloading: 0.0854 s/iter. Inference: 10.3862 s/iter. Eval: 4.9280 s/iter. Total: 15.4000 s/iter. ETA=0:14:22
43
91
34
51
25
[32m[06/13 10:51:38 d2.evaluation.evaluator]: [0mInference done 17/72. Dataloading: 0.0848 s/iter. Inference: 10.5248 s/iter. Eval: 4.9936 s/iter. Total: 15.6035 s/iter. ETA=0:14:18
37
43
34
51
25
36
31
97
31
25
87
25
91
43
34
92
[32m[06/13 10:51:58 d2.evaluation.evaluator]: [0mInference done 19/72. Dataloading: 0.0766 s/iter. Inference: 9.9698 s/iter. Eval: 4.7404 s/iter. Total: 14.7871 s/iter. ETA=0:13:03
43
34
28
51
36
[32m[06/13 10:52:16 d2.evaluation.evaluator]: [0mInference done 20/72. Dataloading: 0.0791 s/iter. Inference: 10.1503 s/iter. Eval: 4.8266 s/iter. Total: 15.0563 s/iter. ETA=0:13:02
43
34
55
25
97
28
[32m[06/13 10:52:35 d2.evaluation.evaluator]: [0mInference done 21/72. Dataloading: 0.0794 s/iter. Inference: 10.2849 s/iter. Eval: 4.8994 s/iter. Total: 15.2640 s/iter. ETA=0:12:58
43
34
36
97
28
28
28
28
28
[32m[06/13 10:52:53 d2.evaluation.evaluator]: [0mInference done 22/72. Dataloading: 0.0851 s/iter. Inference: 10.3999 s/iter. Eval: 4.9640 s/iter. Total: 15.4493 s/iter. ETA=0:12:52
43
34
51
97
84
36
28
[32m[06/13 10:53:11 d2.evaluation.evaluator]: [0mInference done 23/72. Dataloading: 0.0851 s/iter. Inference: 10.4866 s/iter. Eval: 5.0039 s/iter. Total: 15.5758 s/iter. ETA=0:12:43
43
34
84
36
97
28
36
[32m[06/13 10:53:30 d2.evaluation.evaluator]: [0mInference done 24/72. Dataloading: 0.0881 s/iter. Inference: 10.5923 s/iter. Eval: 5.0763 s/iter. Total: 15.7571 s/iter. ETA=0:12:36
43
34
25
84
51
36
36
[32m[06/13 10:53:48 d2.evaluation.evaluator]: [0mInference done 25/72. Dataloading: 0.0900 s/iter. Inference: 10.6570 s/iter. Eval: 5.1043 s/iter. Total: 15.8517 s/iter. ETA=0:12:25
43
34
47
84
72
51
[32m[06/13 10:54:05 d2.evaluation.evaluator]: [0mInference done 26/72. Dataloading: 0.0906 s/iter. Inference: 10.6968 s/iter. Eval: 5.1255 s/iter. Total: 15.9132 s/iter. ETA=0:12:12
43
34
51
[32m[06/13 10:54:23 d2.evaluation.evaluator]: [0mInference done 27/72. Dataloading: 0.0896 s/iter. Inference: 10.7708 s/iter. Eval: 5.1508 s/iter. Total: 16.0115 s/iter. ETA=0:12:00
43
34
47
52
28
[32m[06/13 10:54:36 d2.evaluation.evaluator]: [0mInference done 28/72. Dataloading: 0.0893 s/iter. Inference: 10.8299 s/iter. Eval: 4.9586 s/iter. Total: 15.8780 s/iter. ETA=0:11:38
43
34
28
28
[32m[06/13 10:54:54 d2.evaluation.evaluator]: [0mInference done 29/72. Dataloading: 0.0863 s/iter. Inference: 10.8828 s/iter. Eval: 4.9967 s/iter. Total: 15.9662 s/iter. ETA=0:11:26
43
34
36
52
25
37
47
25
[32m[06/13 10:55:12 d2.evaluation.evaluator]: [0mInference done 30/72. Dataloading: 0.0862 s/iter. Inference: 10.9334 s/iter. Eval: 5.0279 s/iter. Total: 16.0479 s/iter. ETA=0:11:14
43
51
34
[32m[06/13 10:55:23 d2.evaluation.evaluator]: [0mInference done 31/72. Dataloading: 0.0855 s/iter. Inference: 10.7937 s/iter. Eval: 4.9672 s/iter. Total: 15.8467 s/iter. ETA=0:10:49
43
34
25
55
36
28
[32m[06/13 10:55:41 d2.evaluation.evaluator]: [0mInference done 32/72. Dataloading: 0.0856 s/iter. Inference: 10.8595 s/iter. Eval: 4.9953 s/iter. Total: 15.9407 s/iter. ETA=0:10:37
43
34
25
25
25
28
47
97
[32m[06/13 10:56:00 d2.evaluation.evaluator]: [0mInference done 33/72. Dataloading: 0.0864 s/iter. Inference: 10.9256 s/iter. Eval: 5.0264 s/iter. Total: 16.0388 s/iter. ETA=0:10:25
43
34
36
25
91
25
97
25
[32m[06/13 10:56:18 d2.evaluation.evaluator]: [0mInference done 34/72. Dataloading: 0.0883 s/iter. Inference: 10.9767 s/iter. Eval: 5.0529 s/iter. Total: 16.1182 s/iter. ETA=0:10:12
43
34
25
25
97
[32m[06/13 10:56:37 d2.evaluation.evaluator]: [0mInference done 35/72. Dataloading: 0.0885 s/iter. Inference: 11.0378 s/iter. Eval: 5.0805 s/iter. Total: 16.2072 s/iter. ETA=0:09:59
43
34
25
25
28
36
28
[32m[06/13 10:56:55 d2.evaluation.evaluator]: [0mInference done 36/72. Dataloading: 0.0883 s/iter. Inference: 11.0818 s/iter. Eval: 5.0997 s/iter. Total: 16.2701 s/iter. ETA=0:09:45
43
34
36
28
28
25
25
25
25
25
[32m[06/13 10:57:14 d2.evaluation.evaluator]: [0mInference done 37/72. Dataloading: 0.0883 s/iter. Inference: 11.1448 s/iter. Eval: 5.1205 s/iter. Total: 16.3539 s/iter. ETA=0:09:32
43
34
25
25
51
36
[32m[06/13 10:57:32 d2.evaluation.evaluator]: [0mInference done 38/72. Dataloading: 0.0876 s/iter. Inference: 11.1867 s/iter. Eval: 5.1438 s/iter. Total: 16.4185 s/iter. ETA=0:09:18
43
34
36
25
25
97
25
[32m[06/13 10:57:51 d2.evaluation.evaluator]: [0mInference done 39/72. Dataloading: 0.0870 s/iter. Inference: 11.2371 s/iter. Eval: 5.1555 s/iter. Total: 16.4799 s/iter. ETA=0:09:03
43
34
25
97
36
36
25
[32m[06/13 10:58:09 d2.evaluation.evaluator]: [0mInference done 40/72. Dataloading: 0.0871 s/iter. Inference: 11.2693 s/iter. Eval: 5.1685 s/iter. Total: 16.5252 s/iter. ETA=0:08:48
43
34
36
25
97
25
89
[32m[06/13 10:58:27 d2.evaluation.evaluator]: [0mInference done 41/72. Dataloading: 0.0868 s/iter. Inference: 11.3047 s/iter. Eval: 5.1833 s/iter. Total: 16.5752 s/iter. ETA=0:08:33
43
34
28
89
47
28
36
92
25
25
[32m[06/13 10:58:42 d2.evaluation.evaluator]: [0mInference done 42/72. Dataloading: 0.0864 s/iter. Inference: 11.2605 s/iter. Eval: 5.1646 s/iter. Total: 16.5119 s/iter. ETA=0:08:15
43
34
36
52
28
28
47
28
97
28
[32m[06/13 10:59:00 d2.evaluation.evaluator]: [0mInference done 43/72. Dataloading: 0.0851 s/iter. Inference: 11.2988 s/iter. Eval: 5.1898 s/iter. Total: 16.5740 s/iter. ETA=0:08:00
34
43
28
28
28
28
36
[32m[06/13 10:59:19 d2.evaluation.evaluator]: [0mInference done 44/72. Dataloading: 0.0850 s/iter. Inference: 11.3417 s/iter. Eval: 5.2095 s/iter. Total: 16.6365 s/iter. ETA=0:07:45
43
34
47
47
25
25
28
28
[32m[06/13 10:59:38 d2.evaluation.evaluator]: [0mInference done 45/72. Dataloading: 0.0851 s/iter. Inference: 11.3779 s/iter. Eval: 5.2251 s/iter. Total: 16.6884 s/iter. ETA=0:07:30
43
34
91
36
48
[32m[06/13 10:59:47 d2.evaluation.evaluator]: [0mInference done 46/72. Dataloading: 0.0842 s/iter. Inference: 11.2468 s/iter. Eval: 5.1673 s/iter. Total: 16.4988 s/iter. ETA=0:07:08
43
34
28
37
[32m[06/13 11:00:06 d2.evaluation.evaluator]: [0mInference done 47/72. Dataloading: 0.0839 s/iter. Inference: 11.2945 s/iter. Eval: 5.1865 s/iter. Total: 16.5653 s/iter. ETA=0:06:54
43
34
47
28
25
[32m[06/13 11:00:25 d2.evaluation.evaluator]: [0mInference done 48/72. Dataloading: 0.0853 s/iter. Inference: 11.3314 s/iter. Eval: 5.2030 s/iter. Total: 16.6200 s/iter. ETA=0:06:38
34
43
55
47
[32m[06/13 11:00:44 d2.evaluation.evaluator]: [0mInference done 49/72. Dataloading: 0.0862 s/iter. Inference: 11.3615 s/iter. Eval: 5.2151 s/iter. Total: 16.6632 s/iter. ETA=0:06:23
43
34
91
28
37
28
51
[32m[06/13 11:00:53 d2.evaluation.evaluator]: [0mInference done 50/72. Dataloading: 0.0868 s/iter. Inference: 11.2475 s/iter. Eval: 5.1630 s/iter. Total: 16.4977 s/iter. ETA=0:06:02
43
34
25
91
28
36
[32m[06/13 11:01:12 d2.evaluation.evaluator]: [0mInference done 51/72. Dataloading: 0.0870 s/iter. Inference: 11.2910 s/iter. Eval: 5.1791 s/iter. Total: 16.5575 s/iter. ETA=0:05:47
43
34
25
25
36
47
55
55
25
97
[32m[06/13 11:01:31 d2.evaluation.evaluator]: [0mInference done 52/72. Dataloading: 0.0874 s/iter. Inference: 11.3257 s/iter. Eval: 5.1946 s/iter. Total: 16.6080 s/iter. ETA=0:05:32
43
34
36
84
37
36
25
47
[32m[06/13 11:01:50 d2.evaluation.evaluator]: [0mInference done 53/72. Dataloading: 0.0875 s/iter. Inference: 11.3607 s/iter. Eval: 5.2079 s/iter. Total: 16.6565 s/iter. ETA=0:05:16
43
34
36
25
47
37
55
25
97
[32m[06/13 11:02:00 d2.evaluation.evaluator]: [0mInference done 54/72. Dataloading: 0.0868 s/iter. Inference: 11.2586 s/iter. Eval: 5.1640 s/iter. Total: 16.5097 s/iter. ETA=0:04:57
43
34
36
97
55
36
37
[32m[06/13 11:02:18 d2.evaluation.evaluator]: [0mInference done 55/72. Dataloading: 0.0874 s/iter. Inference: 11.2870 s/iter. Eval: 5.1777 s/iter. Total: 16.5524 s/iter. ETA=0:04:41
43
34
47
47
36
28
47
28
28
55
28
25
47
[32m[06/13 11:02:37 d2.evaluation.evaluator]: [0mInference done 56/72. Dataloading: 0.0879 s/iter. Inference: 11.3226 s/iter. Eval: 5.1919 s/iter. Total: 16.6027 s/iter. ETA=0:04:25
43
34
36
47
47
25
28
[32m[06/13 11:02:56 d2.evaluation.evaluator]: [0mInference done 57/72. Dataloading: 0.0886 s/iter. Inference: 11.3447 s/iter. Eval: 5.2136 s/iter. Total: 16.6473 s/iter. ETA=0:04:09
43
34
52
28
28
72
47
[32m[06/13 11:03:15 d2.evaluation.evaluator]: [0mInference done 58/72. Dataloading: 0.0890 s/iter. Inference: 11.3737 s/iter. Eval: 5.2255 s/iter. Total: 16.6885 s/iter. ETA=0:03:53
43
34
47
36
28
47
47
28
36
28
[32m[06/13 11:03:33 d2.evaluation.evaluator]: [0mInference done 59/72. Dataloading: 0.0897 s/iter. Inference: 11.3875 s/iter. Eval: 5.2324 s/iter. Total: 16.7100 s/iter. ETA=0:03:37
43
34
37
52
25
51
51
25
76
[32m[06/13 11:03:51 d2.evaluation.evaluator]: [0mInference done 60/72. Dataloading: 0.0892 s/iter. Inference: 11.3986 s/iter. Eval: 5.2387 s/iter. Total: 16.7268 s/iter. ETA=0:03:20
43
34
28
89
91
47
[32m[06/13 11:04:08 d2.evaluation.evaluator]: [0mInference done 61/72. Dataloading: 0.0881 s/iter. Inference: 11.4140 s/iter. Eval: 5.2460 s/iter. Total: 16.7485 s/iter. ETA=0:03:04
43
34
36
89
28
[32m[06/13 11:04:27 d2.evaluation.evaluator]: [0mInference done 62/72. Dataloading: 0.0887 s/iter. Inference: 11.4313 s/iter. Eval: 5.2542 s/iter. Total: 16.7746 s/iter. ETA=0:02:47
34
43
91
84
47
[32m[06/13 11:04:45 d2.evaluation.evaluator]: [0mInference done 63/72. Dataloading: 0.0897 s/iter. Inference: 11.4554 s/iter. Eval: 5.2629 s/iter. Total: 16.8084 s/iter. ETA=0:02:31
34
43
37
28
28
28
[32m[06/13 11:05:04 d2.evaluation.evaluator]: [0mInference done 64/72. Dataloading: 0.0898 s/iter. Inference: 11.4776 s/iter. Eval: 5.2766 s/iter. Total: 16.8443 s/iter. ETA=0:02:14
34
43
[32m[06/13 11:05:24 d2.evaluation.evaluator]: [0mInference done 65/72. Dataloading: 0.0929 s/iter. Inference: 11.5034 s/iter. Eval: 5.2875 s/iter. Total: 16.8842 s/iter. ETA=0:01:58
43
34
51
47
25
91
28
37
37
[32m[06/13 11:05:35 d2.evaluation.evaluator]: [0mInference done 66/72. Dataloading: 0.0918 s/iter. Inference: 11.4362 s/iter. Eval: 5.2579 s/iter. Total: 16.7863 s/iter. ETA=0:01:40
43
34
36
47
37
28
[32m[06/13 11:05:54 d2.evaluation.evaluator]: [0mInference done 67/72. Dataloading: 0.0926 s/iter. Inference: 11.4687 s/iter. Eval: 5.2697 s/iter. Total: 16.8314 s/iter. ETA=0:01:24
43
34
84
51
49
[32m[06/13 11:06:13 d2.evaluation.evaluator]: [0mInference done 68/72. Dataloading: 0.0936 s/iter. Inference: 11.4923 s/iter. Eval: 5.2807 s/iter. Total: 16.8669 s/iter. ETA=0:01:07
43
34
36
84
[32m[06/13 11:06:32 d2.evaluation.evaluator]: [0mInference done 69/72. Dataloading: 0.0944 s/iter. Inference: 11.5144 s/iter. Eval: 5.2919 s/iter. Total: 16.9010 s/iter. ETA=0:00:50
43
34
36
25
25
49
[32m[06/13 11:06:51 d2.evaluation.evaluator]: [0mInference done 70/72. Dataloading: 0.0945 s/iter. Inference: 11.5364 s/iter. Eval: 5.3012 s/iter. Total: 16.9324 s/iter. ETA=0:00:33
43
34
36
25
51
[32m[06/13 11:07:11 d2.evaluation.evaluator]: [0mInference done 71/72. Dataloading: 0.0946 s/iter. Inference: 11.5602 s/iter. Eval: 5.3140 s/iter. Total: 16.9691 s/iter. ETA=0:00:16
43
34
72
51
25
37
97
28
87
[32m[06/13 11:07:13 d2.evaluation.evaluator]: [0mTotal inference time: 0:18:42.647321 (16.755930 s / iter per device, on 1 devices)
[32m[06/13 11:07:13 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:12:44 (11.414771 s / iter per device, on 1 devices)
  0%|                                                                                                                                                                                                                                | 0/72 [14:58<?, ?it/s]
Traceback (most recent call last):
  File "/home/connecteve/miniconda3/envs/mm-or/lib/python3.10/multiprocessing/pool.py", line 856, in next
    item = self._items.popleft()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/connecteve/intern-brendon/MM-OR/panoptic_segmentation/train_net_video.py", line 414, in <module>
    main(args)
  File "/home/connecteve/intern-brendon/MM-OR/panoptic_segmentation/train_net_video.py", line 399, in main
    res = Trainer.test(cfg, model)
  File "/home/connecteve/intern-brendon/MM-OR/panoptic_segmentation/train_net_video.py", line 305, in test
    results_i = inference_on_dataset(model, data_loader, evaluator)
  File "/home/connecteve/miniconda3/envs/mm-or/lib/python3.10/site-packages/detectron2/evaluation/evaluator.py", line 204, in inference_on_dataset
    results = evaluator.evaluate()
  File "/home/connecteve/intern-brendon/MM-OR/panoptic_segmentation/dvis_Plus/data_video/vps_eval.py", line 346, in evaluate
    vpq_all_, vpq_thing_, vpq_stuff_, results = vpq_compute_parallel(
  File "/home/connecteve/intern-brendon/MM-OR/panoptic_segmentation/utils/eval_vpq_vspw.py", line 287, in vpq_compute_parallel
    for tmp in tqdm(p.imap(partial(vpq_compute_single_core, categories, nframes), gt_pred_split, chunksize=max((len(gt_pred_split) // num_processes // 2), 1)), total=len(gt_pred_split)):
  File "/home/connecteve/miniconda3/envs/mm-or/lib/python3.10/site-packages/tqdm/std.py", line 1181, in __iter__
    for obj in iterable:
  File "/home/connecteve/miniconda3/envs/mm-or/lib/python3.10/multiprocessing/pool.py", line 423, in <genexpr>
    return (item for chunk in result for item in chunk)
  File "/home/connecteve/miniconda3/envs/mm-or/lib/python3.10/multiprocessing/pool.py", line 861, in next
    self._cond.wait(timeout)
  File "/home/connecteve/miniconda3/envs/mm-or/lib/python3.10/threading.py", line 320, in wait
    waiter.acquire()
KeyboardInterrupt
