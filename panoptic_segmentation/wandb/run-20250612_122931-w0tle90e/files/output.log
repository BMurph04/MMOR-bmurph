Frequency file exists. Using weights from frequency file
Using no loss weighting...
[32m[06/12 12:29:33 d2.engine.defaults]: [0mModel:
CTMinVIS(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): VideoMultiScaleMaskedTransformerDecoder_dvisPlus(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(100, 256)
      (query_embed): Embedding(100, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=125, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (reid_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion VideoSetCriterion
      matcher: Matcher VideoHungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 124
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
  (image_matcher): Matcher HungarianMatcher
      cost_class: 2.0
      cost_mask: 5.0
      cost_dice: 5.0
  (cl_plugin): CTCLPlugin()
)
[32m[06/12 12:29:33 fvcore.common.checkpoint]: [0m[Checkpointer] Loading from checkpoints/ctvis_r50_vspw.pth ...
Loading samples: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:00<00:00, 39.39it/s]
Loading samples: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 97997.76it/s]
Take 002_4DOR does not have a json file as ../4D-OR_data/export_holistic_take2_processed/timestamp_to_pcd_and_frames_list.json. Skipping...
Take 006_4DOR does not have a json file as ../4D-OR_data/export_holistic_take6_processed/timestamp_to_pcd_and_frames_list.json. Skipping...
[32m[06/12 12:29:34 d2.data.common]: [0mSerializing 72 elements to byte tensors and concatenating them all ...
[32m[06/12 12:29:34 d2.data.common]: [0mSerialized dataset takes 14.05 MiB
COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[32m[06/12 12:29:34 d2.evaluation.evaluator]: [0mStart inference on 72 batches
/home/connecteve/miniconda3/envs/mm-or/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525541990/work/aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
43
34
51
89
91
37
85
[32m[06/12 12:29:59 d2.evaluation.evaluator]: [0mInference done 1/72. Dataloading: 0.1331 s/iter. Inference: 17.7709 s/iter. Eval: 6.1316 s/iter. Total: 24.0363 s/iter. ETA=0:28:26
43
34
51
91
47
28
28
[32m[06/12 12:30:21 d2.evaluation.evaluator]: [0mInference done 2/72. Dataloading: 0.0667 s/iter. Inference: 16.9462 s/iter. Eval: 6.1859 s/iter. Total: 23.1994 s/iter. ETA=0:27:03
43
34
51
85
[32m[06/12 12:30:44 d2.evaluation.evaluator]: [0mInference done 3/72. Dataloading: 0.1094 s/iter. Inference: 16.7422 s/iter. Eval: 6.2126 s/iter. Total: 23.0647 s/iter. ETA=0:26:31
43
34
51
47
91
25
[32m[06/12 12:31:06 d2.evaluation.evaluator]: [0mInference done 4/72. Dataloading: 0.0821 s/iter. Inference: 16.6269 s/iter. Eval: 6.2307 s/iter. Total: 22.9403 s/iter. ETA=0:25:59
43
51
34
28
[32m[06/12 12:31:24 d2.evaluation.evaluator]: [0mInference done 5/72. Dataloading: 0.0658 s/iter. Inference: 16.5798 s/iter. Eval: 5.2208 s/iter. Total: 21.8670 s/iter. ETA=0:24:25
43
34
37
51
36
36
31
36
36
32
36
84
37
87
43
34
28
47
47
97
[32m[06/12 12:31:43 d2.evaluation.evaluator]: [0mInference done 7/72. Dataloading: 0.0001 s/iter. Inference: 8.8729 s/iter. Eval: 0.7682 s/iter. Total: 9.6412 s/iter. ETA=0:10:26
43
34
91
28
97
[32m[06/12 12:32:06 d2.evaluation.evaluator]: [0mInference done 8/72. Dataloading: 0.0265 s/iter. Inference: 11.3409 s/iter. Eval: 2.5344 s/iter. Total: 13.9019 s/iter. ETA=0:14:49
43
34
47
28
[32m[06/12 12:32:28 d2.evaluation.evaluator]: [0mInference done 9/72. Dataloading: 0.0200 s/iter. Inference: 12.5784 s/iter. Eval: 3.4103 s/iter. Total: 16.0089 s/iter. ETA=0:16:48
43
34
91
28
47
[32m[06/12 12:32:50 d2.evaluation.evaluator]: [0mInference done 10/72. Dataloading: 0.0161 s/iter. Inference: 13.2957 s/iter. Eval: 3.9461 s/iter. Total: 17.2582 s/iter. ETA=0:17:50
34
43
91
47
28
[32m[06/12 12:33:13 d2.evaluation.evaluator]: [0mInference done 11/72. Dataloading: 0.0319 s/iter. Inference: 13.8418 s/iter. Eval: 4.2579 s/iter. Total: 18.1319 s/iter. ETA=0:18:26
43
34
37
72
97
32
71
37
47
43
34
51
37
91
85
[32m[06/12 12:33:37 d2.evaluation.evaluator]: [0mInference done 13/72. Dataloading: 0.0242 s/iter. Inference: 12.6908 s/iter. Eval: 3.9921 s/iter. Total: 16.7074 s/iter. ETA=0:16:25
43
34
85
25
[32m[06/12 12:34:00 d2.evaluation.evaluator]: [0mInference done 14/72. Dataloading: 0.0216 s/iter. Inference: 13.0833 s/iter. Eval: 4.2473 s/iter. Total: 17.3525 s/iter. ETA=0:16:46
34
43
25
51
[32m[06/12 12:34:23 d2.evaluation.evaluator]: [0mInference done 15/72. Dataloading: 0.0195 s/iter. Inference: 13.4479 s/iter. Eval: 4.4806 s/iter. Total: 17.9484 s/iter. ETA=0:17:03
34
43
72
25
[32m[06/12 12:34:48 d2.evaluation.evaluator]: [0mInference done 16/72. Dataloading: 0.0289 s/iter. Inference: 13.8666 s/iter. Eval: 4.6450 s/iter. Total: 18.5409 s/iter. ETA=0:17:18
43
34
51
28
[32m[06/12 12:35:10 d2.evaluation.evaluator]: [0mInference done 17/72. Dataloading: 0.0267 s/iter. Inference: 14.0582 s/iter. Eval: 4.7793 s/iter. Total: 18.8646 s/iter. ETA=0:17:17
34
43
37
51
25
72
25
87
25
35
97
31
36
43
34
47
72
[32m[06/12 12:35:35 d2.evaluation.evaluator]: [0mInference done 19/72. Dataloading: 0.0246 s/iter. Inference: 13.3877 s/iter. Eval: 4.5591 s/iter. Total: 17.9718 s/iter. ETA=0:15:52
43
34
47
36
48
28
37
[32m[06/12 12:35:58 d2.evaluation.evaluator]: [0mInference done 20/72. Dataloading: 0.0231 s/iter. Inference: 13.5940 s/iter. Eval: 4.6540 s/iter. Total: 18.2715 s/iter. ETA=0:15:50
43
34
91
35
[32m[06/12 12:36:21 d2.evaluation.evaluator]: [0mInference done 21/72. Dataloading: 0.0217 s/iter. Inference: 13.7712 s/iter. Eval: 4.7589 s/iter. Total: 18.5521 s/iter. ETA=0:15:46
43
34
97
36
28
28
35
[32m[06/12 12:36:43 d2.evaluation.evaluator]: [0mInference done 22/72. Dataloading: 0.0204 s/iter. Inference: 13.9302 s/iter. Eval: 4.8319 s/iter. Total: 18.7830 s/iter. ETA=0:15:39
43
34
35
47
84
28
28
[32m[06/12 12:37:05 d2.evaluation.evaluator]: [0mInference done 23/72. Dataloading: 0.0193 s/iter. Inference: 14.0534 s/iter. Eval: 4.8918 s/iter. Total: 18.9649 s/iter. ETA=0:15:29
43
34
36
35
97
[32m[06/12 12:37:28 d2.evaluation.evaluator]: [0mInference done 24/72. Dataloading: 0.0349 s/iter. Inference: 14.1647 s/iter. Eval: 4.9646 s/iter. Total: 19.1646 s/iter. ETA=0:15:19
43
34
25
84
28
51
91
48
25
28
[32m[06/12 12:37:50 d2.evaluation.evaluator]: [0mInference done 25/72. Dataloading: 0.0333 s/iter. Inference: 14.2705 s/iter. Eval: 5.0152 s/iter. Total: 19.3194 s/iter. ETA=0:15:08
43
34
28
[32m[06/12 12:38:12 d2.evaluation.evaluator]: [0mInference done 26/72. Dataloading: 0.0317 s/iter. Inference: 14.3534 s/iter. Eval: 5.0602 s/iter. Total: 19.4457 s/iter. ETA=0:14:54
43
34
52
28
35
[32m[06/12 12:38:35 d2.evaluation.evaluator]: [0mInference done 27/72. Dataloading: 0.0344 s/iter. Inference: 14.4550 s/iter. Eval: 5.1074 s/iter. Total: 19.5972 s/iter. ETA=0:14:41
43
34
28
28
28
51
[32m[06/12 12:38:57 d2.evaluation.evaluator]: [0mInference done 28/72. Dataloading: 0.0330 s/iter. Inference: 14.5395 s/iter. Eval: 5.1397 s/iter. Total: 19.7127 s/iter. ETA=0:14:27
43
34
28
28
[32m[06/12 12:39:20 d2.evaluation.evaluator]: [0mInference done 29/72. Dataloading: 0.0317 s/iter. Inference: 14.6246 s/iter. Eval: 5.1859 s/iter. Total: 19.8426 s/iter. ETA=0:14:13
43
34
51
36
55
25
[32m[06/12 12:39:43 d2.evaluation.evaluator]: [0mInference done 30/72. Dataloading: 0.0304 s/iter. Inference: 14.6988 s/iter. Eval: 5.2226 s/iter. Total: 19.9523 s/iter. ETA=0:13:57
43
34
47
51
51
28
[32m[06/12 12:39:56 d2.evaluation.evaluator]: [0mInference done 31/72. Dataloading: 0.0293 s/iter. Inference: 14.5219 s/iter. Eval: 5.1561 s/iter. Total: 19.7077 s/iter. ETA=0:13:28
43
34
25
25
51
51
25
28
36
[32m[06/12 12:40:19 d2.evaluation.evaluator]: [0mInference done 32/72. Dataloading: 0.0309 s/iter. Inference: 14.6082 s/iter. Eval: 5.1805 s/iter. Total: 19.8200 s/iter. ETA=0:13:12
43
34
28
28
25
28
36
28
[32m[06/12 12:40:41 d2.evaluation.evaluator]: [0mInference done 33/72. Dataloading: 0.0299 s/iter. Inference: 14.6705 s/iter. Eval: 5.2076 s/iter. Total: 19.9085 s/iter. ETA=0:12:56
43
34
51
28
36
25
28
28
[32m[06/12 12:41:04 d2.evaluation.evaluator]: [0mInference done 34/72. Dataloading: 0.0289 s/iter. Inference: 14.7377 s/iter. Eval: 5.2367 s/iter. Total: 20.0038 s/iter. ETA=0:12:40
43
34
51
91
36
28
36
25
51
[32m[06/12 12:41:27 d2.evaluation.evaluator]: [0mInference done 35/72. Dataloading: 0.0322 s/iter. Inference: 14.7865 s/iter. Eval: 5.2742 s/iter. Total: 20.0934 s/iter. ETA=0:12:23
43
34
28
93
36
25
51
51
[32m[06/12 12:41:49 d2.evaluation.evaluator]: [0mInference done 36/72. Dataloading: 0.0311 s/iter. Inference: 14.8316 s/iter. Eval: 5.3043 s/iter. Total: 20.1676 s/iter. ETA=0:12:06
43
34
28
36
25
25
25
[32m[06/12 12:42:12 d2.evaluation.evaluator]: [0mInference done 37/72. Dataloading: 0.0303 s/iter. Inference: 14.8774 s/iter. Eval: 5.3329 s/iter. Total: 20.2410 s/iter. ETA=0:11:48
43
34
51
25
25
36
28
[32m[06/12 12:42:34 d2.evaluation.evaluator]: [0mInference done 38/72. Dataloading: 0.0294 s/iter. Inference: 14.9062 s/iter. Eval: 5.3571 s/iter. Total: 20.2932 s/iter. ETA=0:11:29
43
34
51
36
25
28
25
25
36
[32m[06/12 12:42:56 d2.evaluation.evaluator]: [0mInference done 39/72. Dataloading: 0.0285 s/iter. Inference: 14.9458 s/iter. Eval: 5.3822 s/iter. Total: 20.3570 s/iter. ETA=0:11:11
43
34
51
36
25
36
36
25
[32m[06/12 12:43:19 d2.evaluation.evaluator]: [0mInference done 40/72. Dataloading: 0.0301 s/iter. Inference: 14.9814 s/iter. Eval: 5.4071 s/iter. Total: 20.4191 s/iter. ETA=0:10:53
43
34
51
91
25
[32m[06/12 12:43:41 d2.evaluation.evaluator]: [0mInference done 41/72. Dataloading: 0.0293 s/iter. Inference: 15.0204 s/iter. Eval: 5.4267 s/iter. Total: 20.4768 s/iter. ETA=0:10:34
43
34
91
36
25
25
92
25
28
25
[32m[06/12 12:43:59 d2.evaluation.evaluator]: [0mInference done 42/72. Dataloading: 0.0286 s/iter. Inference: 14.9741 s/iter. Eval: 5.4111 s/iter. Total: 20.4144 s/iter. ETA=0:10:12
43
34
28
47
47
47
91
97
[32m[06/12 12:44:22 d2.evaluation.evaluator]: [0mInference done 43/72. Dataloading: 0.0293 s/iter. Inference: 15.0275 s/iter. Eval: 5.4290 s/iter. Total: 20.4863 s/iter. ETA=0:09:54
34
43
28
48
25
[32m[06/12 12:44:45 d2.evaluation.evaluator]: [0mInference done 44/72. Dataloading: 0.0285 s/iter. Inference: 15.0566 s/iter. Eval: 5.4465 s/iter. Total: 20.5322 s/iter. ETA=0:09:34
43
34
47
28
28
[32m[06/12 12:45:07 d2.evaluation.evaluator]: [0mInference done 45/72. Dataloading: 0.0279 s/iter. Inference: 15.0886 s/iter. Eval: 5.4706 s/iter. Total: 20.5876 s/iter. ETA=0:09:15
43
34
28
48
47
28
91
[32m[06/12 12:45:18 d2.evaluation.evaluator]: [0mInference done 46/72. Dataloading: 0.0272 s/iter. Inference: 14.9141 s/iter. Eval: 5.4156 s/iter. Total: 20.3575 s/iter. ETA=0:08:49
43
34
37
91
28
28
28
[32m[06/12 12:45:42 d2.evaluation.evaluator]: [0mInference done 47/72. Dataloading: 0.0266 s/iter. Inference: 14.9590 s/iter. Eval: 5.4383 s/iter. Total: 20.4245 s/iter. ETA=0:08:30
43
34
91
[32m[06/12 12:46:04 d2.evaluation.evaluator]: [0mInference done 48/72. Dataloading: 0.0281 s/iter. Inference: 14.9879 s/iter. Eval: 5.4595 s/iter. Total: 20.4761 s/iter. ETA=0:08:11
34
43
91
25
[32m[06/12 12:46:27 d2.evaluation.evaluator]: [0mInference done 49/72. Dataloading: 0.0275 s/iter. Inference: 15.0211 s/iter. Eval: 5.4757 s/iter. Total: 20.5249 s/iter. ETA=0:07:52
43
34
28
91
37
[32m[06/12 12:46:38 d2.evaluation.evaluator]: [0mInference done 50/72. Dataloading: 0.0269 s/iter. Inference: 14.8722 s/iter. Eval: 5.4216 s/iter. Total: 20.3212 s/iter. ETA=0:07:27
43
34
25
28
28
25
[32m[06/12 12:47:01 d2.evaluation.evaluator]: [0mInference done 51/72. Dataloading: 0.0280 s/iter. Inference: 14.9166 s/iter. Eval: 5.4368 s/iter. Total: 20.3820 s/iter. ETA=0:07:08
43
34
36
84
25
25
97
[32m[06/12 12:47:24 d2.evaluation.evaluator]: [0mInference done 52/72. Dataloading: 0.0274 s/iter. Inference: 14.9440 s/iter. Eval: 5.4510 s/iter. Total: 20.4230 s/iter. ETA=0:06:48
43
34
36
36
84
25
28
[32m[06/12 12:47:46 d2.evaluation.evaluator]: [0mInference done 53/72. Dataloading: 0.0269 s/iter. Inference: 14.9705 s/iter. Eval: 5.4665 s/iter. Total: 20.4644 s/iter. ETA=0:06:28
43
34
36
25
28
91
97
54
[32m[06/12 12:47:57 d2.evaluation.evaluator]: [0mInference done 54/72. Dataloading: 0.0264 s/iter. Inference: 14.8322 s/iter. Eval: 5.4174 s/iter. Total: 20.2765 s/iter. ETA=0:06:04
43
34
36
47
25
97
[32m[06/12 12:48:20 d2.evaluation.evaluator]: [0mInference done 55/72. Dataloading: 0.0259 s/iter. Inference: 14.8611 s/iter. Eval: 5.4309 s/iter. Total: 20.3184 s/iter. ETA=0:05:45
43
34
36
49
36
28
25
[32m[06/12 12:48:42 d2.evaluation.evaluator]: [0mInference done 56/72. Dataloading: 0.0266 s/iter. Inference: 14.8861 s/iter. Eval: 5.4457 s/iter. Total: 20.3589 s/iter. ETA=0:05:25
43
34
47
28
47
28
27
52
[32m[06/12 12:49:05 d2.evaluation.evaluator]: [0mInference done 57/72. Dataloading: 0.0261 s/iter. Inference: 14.9181 s/iter. Eval: 5.4595 s/iter. Total: 20.4042 s/iter. ETA=0:05:06
43
34
47
52
51
28
[32m[06/12 12:49:27 d2.evaluation.evaluator]: [0mInference done 58/72. Dataloading: 0.0256 s/iter. Inference: 14.9407 s/iter. Eval: 5.4749 s/iter. Total: 20.4416 s/iter. ETA=0:04:46
34
43
28
28
28
25
[32m[06/12 12:49:50 d2.evaluation.evaluator]: [0mInference done 59/72. Dataloading: 0.0272 s/iter. Inference: 14.9661 s/iter. Eval: 5.4890 s/iter. Total: 20.4828 s/iter. ETA=0:04:26
43
34
25
37
51
84
51
[32m[06/12 12:50:12 d2.evaluation.evaluator]: [0mInference done 60/72. Dataloading: 0.0267 s/iter. Inference: 14.9837 s/iter. Eval: 5.5019 s/iter. Total: 20.5128 s/iter. ETA=0:04:06
43
34
89
28
91
37
[32m[06/12 12:50:35 d2.evaluation.evaluator]: [0mInference done 61/72. Dataloading: 0.0262 s/iter. Inference: 15.0111 s/iter. Eval: 5.5171 s/iter. Total: 20.5549 s/iter. ETA=0:03:46
34
43
91
28
28
[32m[06/12 12:50:57 d2.evaluation.evaluator]: [0mInference done 62/72. Dataloading: 0.0258 s/iter. Inference: 15.0356 s/iter. Eval: 5.5259 s/iter. Total: 20.5878 s/iter. ETA=0:03:25
34
43
28
28
91
[32m[06/12 12:51:20 d2.evaluation.evaluator]: [0mInference done 63/72. Dataloading: 0.0253 s/iter. Inference: 15.0577 s/iter. Eval: 5.5403 s/iter. Total: 20.6240 s/iter. ETA=0:03:05
43
34
37
91
28
[32m[06/12 12:51:43 d2.evaluation.evaluator]: [0mInference done 64/72. Dataloading: 0.0271 s/iter. Inference: 15.0782 s/iter. Eval: 5.5511 s/iter. Total: 20.6570 s/iter. ETA=0:02:45
34
43
[32m[06/12 12:52:05 d2.evaluation.evaluator]: [0mInference done 65/72. Dataloading: 0.0267 s/iter. Inference: 15.1000 s/iter. Eval: 5.5567 s/iter. Total: 20.6840 s/iter. ETA=0:02:24
34
43
91
36
28
28
28
28
[32m[06/12 12:52:18 d2.evaluation.evaluator]: [0mInference done 66/72. Dataloading: 0.0263 s/iter. Inference: 15.0164 s/iter. Eval: 5.5247 s/iter. Total: 20.5680 s/iter. ETA=0:02:03
43
34
37
[32m[06/12 12:52:42 d2.evaluation.evaluator]: [0mInference done 67/72. Dataloading: 0.0267 s/iter. Inference: 15.0490 s/iter. Eval: 5.5327 s/iter. Total: 20.6090 s/iter. ETA=0:01:43
43
34
84
91
49
[32m[06/12 12:53:04 d2.evaluation.evaluator]: [0mInference done 68/72. Dataloading: 0.0263 s/iter. Inference: 15.0681 s/iter. Eval: 5.5407 s/iter. Total: 20.6357 s/iter. ETA=0:01:22
43
34
36
84
51
[32m[06/12 12:53:26 d2.evaluation.evaluator]: [0mInference done 69/72. Dataloading: 0.0259 s/iter. Inference: 15.0847 s/iter. Eval: 5.5474 s/iter. Total: 20.6586 s/iter. ETA=0:01:01
43
34
36
84
27
28
[32m[06/12 12:53:49 d2.evaluation.evaluator]: [0mInference done 70/72. Dataloading: 0.0255 s/iter. Inference: 15.1096 s/iter. Eval: 5.5579 s/iter. Total: 20.6936 s/iter. ETA=0:00:41
43
34
36
51
25
51
[32m[06/12 12:54:11 d2.evaluation.evaluator]: [0mInference done 71/72. Dataloading: 0.0251 s/iter. Inference: 15.1287 s/iter. Eval: 5.5670 s/iter. Total: 20.7213 s/iter. ETA=0:00:20
43
34
84
37
72
37
51
87
47
27
97
[32m[06/12 12:54:15 d2.evaluation.evaluator]: [0mTotal inference time: 0:22:50.826382 (20.460095 s / iter per device, on 1 devices)
[32m[06/12 12:54:15 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:40 (14.938164 s / iter per device, on 1 devices)
Traceback (most recent call last):
  File "/home/connecteve/intern-brendon/MM-OR/panoptic_segmentation/train_net_video.py", line 414, in <module>
    main(args)
  File "/home/connecteve/intern-brendon/MM-OR/panoptic_segmentation/train_net_video.py", line 399, in main
    res = Trainer.test(cfg, model)
  File "/home/connecteve/intern-brendon/MM-OR/panoptic_segmentation/train_net_video.py", line 305, in test
    results_i = inference_on_dataset(model, data_loader, evaluator)
  File "/home/connecteve/miniconda3/envs/mm-or/lib/python3.10/site-packages/detectron2/evaluation/evaluator.py", line 204, in inference_on_dataset
    results = evaluator.evaluate()
  File "/home/connecteve/intern-brendon/MM-OR/panoptic_segmentation/dvis_Plus/data_video/vps_eval.py", line 298, in evaluate
    with open(f'datasets/hybridor_ground_truth_{dataset_split}.json', 'r') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'datasets/hybridor_ground_truth_test.json'
