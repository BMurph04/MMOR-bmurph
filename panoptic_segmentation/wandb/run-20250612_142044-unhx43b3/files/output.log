Frequency file exists. Using weights from frequency file
Using no loss weighting...
[32m[06/12 14:20:45 d2.engine.defaults]: [0mModel:
CTMinVIS(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): VideoMultiScaleMaskedTransformerDecoder_dvisPlus(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(100, 256)
      (query_embed): Embedding(100, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=125, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (reid_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion VideoSetCriterion
      matcher: Matcher VideoHungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 124
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
  (image_matcher): Matcher HungarianMatcher
      cost_class: 2.0
      cost_mask: 5.0
      cost_dice: 5.0
  (cl_plugin): CTCLPlugin()
)
[32m[06/12 14:20:45 fvcore.common.checkpoint]: [0m[Checkpointer] Loading from checkpoints/ctvis_r50_vspw.pth ...
Loading samples: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 37.92it/s]
[32m[06/12 14:20:47 d2.data.common]: [0mSerializing 72 elements to byte tensors and concatenating them all ...
[32m[06/12 14:20:47 d2.data.common]: [0mSerialized dataset takes 14.05 MiB
COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[32m[06/12 14:20:47 d2.evaluation.evaluator]: [0mStart inference on 72 batches
/home/connecteve/miniconda3/envs/mm-or/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525541990/work/aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
43
34
51
89
91
37
85
[32m[06/12 14:21:08 d2.evaluation.evaluator]: [0mInference done 1/72. Dataloading: 0.1543 s/iter. Inference: 16.8096 s/iter. Eval: 4.5426 s/iter. Total: 21.5071 s/iter. ETA=0:25:27
43
34
51
91
47
28
28
[32m[06/12 14:21:30 d2.evaluation.evaluator]: [0mInference done 2/72. Dataloading: 0.0774 s/iter. Inference: 16.2775 s/iter. Eval: 5.4579 s/iter. Total: 21.8133 s/iter. ETA=0:25:26
43
34
51
85
[32m[06/12 14:21:53 d2.evaluation.evaluator]: [0mInference done 3/72. Dataloading: 0.1049 s/iter. Inference: 16.3629 s/iter. Eval: 5.7264 s/iter. Total: 22.1976 s/iter. ETA=0:25:31
43
34
51
47
91
25
[32m[06/12 14:22:16 d2.evaluation.evaluator]: [0mInference done 4/72. Dataloading: 0.0788 s/iter. Inference: 16.4405 s/iter. Eval: 5.8681 s/iter. Total: 22.3901 s/iter. ETA=0:25:22
43
51
34
28
[32m[06/12 14:22:34 d2.evaluation.evaluator]: [0mInference done 5/72. Dataloading: 0.0631 s/iter. Inference: 16.4677 s/iter. Eval: 4.9660 s/iter. Total: 21.4990 s/iter. ETA=0:24:00
43
34
37
51
36
36
31
36
36
32
36
84
37
87
43
34
28
47
47
97
[32m[06/12 14:22:54 d2.evaluation.evaluator]: [0mInference done 7/72. Dataloading: 0.0001 s/iter. Inference: 9.1228 s/iter. Eval: 0.7735 s/iter. Total: 9.8964 s/iter. ETA=0:10:43
43
34
91
28
97
[32m[06/12 14:23:17 d2.evaluation.evaluator]: [0mInference done 8/72. Dataloading: 0.0181 s/iter. Inference: 11.4896 s/iter. Eval: 2.6715 s/iter. Total: 14.1794 s/iter. ETA=0:15:07
43
34
47
28
[32m[06/12 14:23:39 d2.evaluation.evaluator]: [0mInference done 9/72. Dataloading: 0.0137 s/iter. Inference: 12.7011 s/iter. Eval: 3.5281 s/iter. Total: 16.2431 s/iter. ETA=0:17:03
43
34
91
28
47
[32m[06/12 14:24:02 d2.evaluation.evaluator]: [0mInference done 10/72. Dataloading: 0.0114 s/iter. Inference: 13.5160 s/iter. Eval: 4.0293 s/iter. Total: 17.5569 s/iter. ETA=0:18:08
34
43
91
47
28
[32m[06/12 14:24:25 d2.evaluation.evaluator]: [0mInference done 11/72. Dataloading: 0.0311 s/iter. Inference: 13.9673 s/iter. Eval: 4.4282 s/iter. Total: 18.4269 s/iter. ETA=0:18:44
43
34
37
72
97
32
71
37
47
43
34
51
37
91
85
[32m[06/12 14:24:50 d2.evaluation.evaluator]: [0mInference done 13/72. Dataloading: 0.0234 s/iter. Inference: 12.8078 s/iter. Eval: 4.1903 s/iter. Total: 17.0219 s/iter. ETA=0:16:44
43
34
85
25
[32m[06/12 14:25:13 d2.evaluation.evaluator]: [0mInference done 14/72. Dataloading: 0.0209 s/iter. Inference: 13.2200 s/iter. Eval: 4.4151 s/iter. Total: 17.6562 s/iter. ETA=0:17:04
34
43
25
51
[32m[06/12 14:25:36 d2.evaluation.evaluator]: [0mInference done 15/72. Dataloading: 0.0189 s/iter. Inference: 13.5455 s/iter. Eval: 4.6206 s/iter. Total: 18.1854 s/iter. ETA=0:17:16
34
43
72
25
[32m[06/12 14:25:59 d2.evaluation.evaluator]: [0mInference done 16/72. Dataloading: 0.0252 s/iter. Inference: 13.8121 s/iter. Eval: 4.7556 s/iter. Total: 18.5933 s/iter. ETA=0:17:21
43
34
51
28
[32m[06/12 14:26:21 d2.evaluation.evaluator]: [0mInference done 17/72. Dataloading: 0.0231 s/iter. Inference: 14.0114 s/iter. Eval: 4.8604 s/iter. Total: 18.8953 s/iter. ETA=0:17:19
34
43
37
51
25
72
25
87
25
35
97
31
36
43
34
47
72
[32m[06/12 14:26:46 d2.evaluation.evaluator]: [0mInference done 19/72. Dataloading: 0.0216 s/iter. Inference: 13.3335 s/iter. Eval: 4.6504 s/iter. Total: 18.0058 s/iter. ETA=0:15:54
43
34
47
36
48
28
37
[32m[06/12 14:27:09 d2.evaluation.evaluator]: [0mInference done 20/72. Dataloading: 0.0202 s/iter. Inference: 13.5486 s/iter. Eval: 4.7576 s/iter. Total: 18.3268 s/iter. ETA=0:15:52
43
34
91
35
[32m[06/12 14:27:32 d2.evaluation.evaluator]: [0mInference done 21/72. Dataloading: 0.0190 s/iter. Inference: 13.7180 s/iter. Eval: 4.8494 s/iter. Total: 18.5867 s/iter. ETA=0:15:47
43
34
97
36
28
28
35
[32m[06/12 14:27:54 d2.evaluation.evaluator]: [0mInference done 22/72. Dataloading: 0.0179 s/iter. Inference: 13.8652 s/iter. Eval: 4.9098 s/iter. Total: 18.7932 s/iter. ETA=0:15:39
43
34
35
47
84
28
28
[32m[06/12 14:28:17 d2.evaluation.evaluator]: [0mInference done 23/72. Dataloading: 0.0169 s/iter. Inference: 14.0361 s/iter. Eval: 4.9796 s/iter. Total: 19.0330 s/iter. ETA=0:15:32
43
34
36
35
97
[32m[06/12 14:28:40 d2.evaluation.evaluator]: [0mInference done 24/72. Dataloading: 0.0361 s/iter. Inference: 14.1419 s/iter. Eval: 5.0611 s/iter. Total: 19.2395 s/iter. ETA=0:15:23
43
34
25
84
28
51
91
48
25
28
[32m[06/12 14:29:02 d2.evaluation.evaluator]: [0mInference done 25/72. Dataloading: 0.0343 s/iter. Inference: 14.2506 s/iter. Eval: 5.1205 s/iter. Total: 19.4058 s/iter. ETA=0:15:12
43
34
28
[32m[06/12 14:29:24 d2.evaluation.evaluator]: [0mInference done 26/72. Dataloading: 0.0328 s/iter. Inference: 14.2961 s/iter. Eval: 5.1697 s/iter. Total: 19.4990 s/iter. ETA=0:14:56
43
34
52
28
35
[32m[06/12 14:29:47 d2.evaluation.evaluator]: [0mInference done 27/72. Dataloading: 0.0368 s/iter. Inference: 14.3996 s/iter. Eval: 5.2260 s/iter. Total: 19.6628 s/iter. ETA=0:14:44
43
34
28
28
28
51
[32m[06/12 14:30:10 d2.evaluation.evaluator]: [0mInference done 28/72. Dataloading: 0.0353 s/iter. Inference: 14.4906 s/iter. Eval: 5.2726 s/iter. Total: 19.7989 s/iter. ETA=0:14:31
43
34
28
28
[32m[06/12 14:30:33 d2.evaluation.evaluator]: [0mInference done 29/72. Dataloading: 0.0339 s/iter. Inference: 14.5759 s/iter. Eval: 5.3158 s/iter. Total: 19.9261 s/iter. ETA=0:14:16
43
34
51
36
55
25
[32m[06/12 14:30:55 d2.evaluation.evaluator]: [0mInference done 30/72. Dataloading: 0.0327 s/iter. Inference: 14.6473 s/iter. Eval: 5.3578 s/iter. Total: 20.0383 s/iter. ETA=0:14:01
43
34
47
51
51
28
[32m[06/12 14:31:09 d2.evaluation.evaluator]: [0mInference done 31/72. Dataloading: 0.0314 s/iter. Inference: 14.4760 s/iter. Eval: 5.2971 s/iter. Total: 19.8050 s/iter. ETA=0:13:32
43
34
25
25
51
51
25
28
36
[32m[06/12 14:31:33 d2.evaluation.evaluator]: [0mInference done 32/72. Dataloading: 0.0340 s/iter. Inference: 14.5704 s/iter. Eval: 5.3326 s/iter. Total: 19.9374 s/iter. ETA=0:13:17
43
34
28
28
25
28
36
28
[32m[06/12 14:31:55 d2.evaluation.evaluator]: [0mInference done 33/72. Dataloading: 0.0328 s/iter. Inference: 14.6381 s/iter. Eval: 5.3593 s/iter. Total: 20.0307 s/iter. ETA=0:13:01
43
34
51
28
36
25
28
28
[32m[06/12 14:32:17 d2.evaluation.evaluator]: [0mInference done 34/72. Dataloading: 0.0317 s/iter. Inference: 14.6939 s/iter. Eval: 5.3810 s/iter. Total: 20.1071 s/iter. ETA=0:12:44
43
34
51
91
36
28
36
25
51
[32m[06/12 14:32:40 d2.evaluation.evaluator]: [0mInference done 35/72. Dataloading: 0.0353 s/iter. Inference: 14.7544 s/iter. Eval: 5.4123 s/iter. Total: 20.2025 s/iter. ETA=0:12:27
43
34
28
93
36
25
51
51
[32m[06/12 14:33:03 d2.evaluation.evaluator]: [0mInference done 36/72. Dataloading: 0.0342 s/iter. Inference: 14.8035 s/iter. Eval: 5.4429 s/iter. Total: 20.2810 s/iter. ETA=0:12:10
43
34
28
36
25
25
25
[32m[06/12 14:33:25 d2.evaluation.evaluator]: [0mInference done 37/72. Dataloading: 0.0332 s/iter. Inference: 14.8469 s/iter. Eval: 5.4620 s/iter. Total: 20.3426 s/iter. ETA=0:11:51
43
34
51
25
25
36
28
[32m[06/12 14:33:48 d2.evaluation.evaluator]: [0mInference done 38/72. Dataloading: 0.0322 s/iter. Inference: 14.8822 s/iter. Eval: 5.4890 s/iter. Total: 20.4039 s/iter. ETA=0:11:33
43
34
51
36
25
28
25
25
36
[32m[06/12 14:34:10 d2.evaluation.evaluator]: [0mInference done 39/72. Dataloading: 0.0313 s/iter. Inference: 14.9167 s/iter. Eval: 5.5130 s/iter. Total: 20.4615 s/iter. ETA=0:11:15
43
34
51
36
25
36
36
25
[32m[06/12 14:34:33 d2.evaluation.evaluator]: [0mInference done 40/72. Dataloading: 0.0339 s/iter. Inference: 14.9566 s/iter. Eval: 5.5302 s/iter. Total: 20.5212 s/iter. ETA=0:10:56
43
34
51
91
25
[32m[06/12 14:34:55 d2.evaluation.evaluator]: [0mInference done 41/72. Dataloading: 0.0330 s/iter. Inference: 15.0001 s/iter. Eval: 5.5465 s/iter. Total: 20.5801 s/iter. ETA=0:10:37
43
34
91
36
25
25
92
25
28
25
[32m[06/12 14:35:13 d2.evaluation.evaluator]: [0mInference done 42/72. Dataloading: 0.0321 s/iter. Inference: 14.9440 s/iter. Eval: 5.5280 s/iter. Total: 20.5045 s/iter. ETA=0:10:15
43
34
28
47
47
47
91
97
[32m[06/12 14:35:37 d2.evaluation.evaluator]: [0mInference done 43/72. Dataloading: 0.0353 s/iter. Inference: 15.0159 s/iter. Eval: 5.5422 s/iter. Total: 20.5939 s/iter. ETA=0:09:57
34
43
28
48
25
[32m[06/12 14:35:59 d2.evaluation.evaluator]: [0mInference done 44/72. Dataloading: 0.0344 s/iter. Inference: 15.0497 s/iter. Eval: 5.5538 s/iter. Total: 20.6384 s/iter. ETA=0:09:37
43
34
47
28
28
[32m[06/12 14:36:21 d2.evaluation.evaluator]: [0mInference done 45/72. Dataloading: 0.0336 s/iter. Inference: 15.0766 s/iter. Eval: 5.5656 s/iter. Total: 20.6762 s/iter. ETA=0:09:18
43
34
28
48
47
28
91
[32m[06/12 14:36:32 d2.evaluation.evaluator]: [0mInference done 46/72. Dataloading: 0.0328 s/iter. Inference: 14.9046 s/iter. Eval: 5.4965 s/iter. Total: 20.4344 s/iter. ETA=0:08:51
43
34
37
91
28
28
28
[32m[06/12 14:36:55 d2.evaluation.evaluator]: [0mInference done 47/72. Dataloading: 0.0320 s/iter. Inference: 14.9567 s/iter. Eval: 5.5125 s/iter. Total: 20.5017 s/iter. ETA=0:08:32
43
34
91
[32m[06/12 14:37:18 d2.evaluation.evaluator]: [0mInference done 48/72. Dataloading: 0.0331 s/iter. Inference: 14.9893 s/iter. Eval: 5.5235 s/iter. Total: 20.5465 s/iter. ETA=0:08:13
34
43
91
25
[32m[06/12 14:37:40 d2.evaluation.evaluator]: [0mInference done 49/72. Dataloading: 0.0324 s/iter. Inference: 15.0176 s/iter. Eval: 5.5342 s/iter. Total: 20.5847 s/iter. ETA=0:07:53
43
34
28
91
37
[32m[06/12 14:37:52 d2.evaluation.evaluator]: [0mInference done 50/72. Dataloading: 0.0317 s/iter. Inference: 14.8758 s/iter. Eval: 5.4741 s/iter. Total: 20.3821 s/iter. ETA=0:07:28
43
34
25
28
28
25
[32m[06/12 14:38:15 d2.evaluation.evaluator]: [0mInference done 51/72. Dataloading: 0.0331 s/iter. Inference: 14.9203 s/iter. Eval: 5.4873 s/iter. Total: 20.4412 s/iter. ETA=0:07:09
43
34
36
84
25
25
97
[32m[06/12 14:38:37 d2.evaluation.evaluator]: [0mInference done 52/72. Dataloading: 0.0324 s/iter. Inference: 14.9513 s/iter. Eval: 5.5000 s/iter. Total: 20.4843 s/iter. ETA=0:06:49
43
34
36
36
84
25
28
[32m[06/12 14:38:59 d2.evaluation.evaluator]: [0mInference done 53/72. Dataloading: 0.0318 s/iter. Inference: 14.9802 s/iter. Eval: 5.5094 s/iter. Total: 20.5219 s/iter. ETA=0:06:29
43
34
36
25
28
91
97
54
[32m[06/12 14:39:11 d2.evaluation.evaluator]: [0mInference done 54/72. Dataloading: 0.0311 s/iter. Inference: 14.8466 s/iter. Eval: 5.4567 s/iter. Total: 20.3349 s/iter. ETA=0:06:06
43
34
36
47
25
97
[32m[06/12 14:39:33 d2.evaluation.evaluator]: [0mInference done 55/72. Dataloading: 0.0305 s/iter. Inference: 14.8783 s/iter. Eval: 5.4680 s/iter. Total: 20.3773 s/iter. ETA=0:05:46
43
34
36
49
36
28
25
[32m[06/12 14:39:55 d2.evaluation.evaluator]: [0mInference done 56/72. Dataloading: 0.0320 s/iter. Inference: 14.8982 s/iter. Eval: 5.4776 s/iter. Total: 20.4083 s/iter. ETA=0:05:26
43
34
47
28
47
28
27
52
[32m[06/12 14:40:17 d2.evaluation.evaluator]: [0mInference done 57/72. Dataloading: 0.0314 s/iter. Inference: 14.9218 s/iter. Eval: 5.4863 s/iter. Total: 20.4400 s/iter. ETA=0:05:06
43
34
47
52
51
28
[32m[06/12 14:40:39 d2.evaluation.evaluator]: [0mInference done 58/72. Dataloading: 0.0308 s/iter. Inference: 14.9490 s/iter. Eval: 5.4936 s/iter. Total: 20.4740 s/iter. ETA=0:04:46
34
43
28
28
28
25
[32m[06/12 14:41:01 d2.evaluation.evaluator]: [0mInference done 59/72. Dataloading: 0.0320 s/iter. Inference: 14.9672 s/iter. Eval: 5.5002 s/iter. Total: 20.4999 s/iter. ETA=0:04:26
43
34
25
37
51
84
51
[32m[06/12 14:41:23 d2.evaluation.evaluator]: [0mInference done 60/72. Dataloading: 0.0314 s/iter. Inference: 14.9831 s/iter. Eval: 5.5038 s/iter. Total: 20.5189 s/iter. ETA=0:04:06
43
34
89
28
91
37
[32m[06/12 14:41:45 d2.evaluation.evaluator]: [0mInference done 61/72. Dataloading: 0.0309 s/iter. Inference: 15.0072 s/iter. Eval: 5.5117 s/iter. Total: 20.5503 s/iter. ETA=0:03:46
34
43
91
28
28
[32m[06/12 14:42:08 d2.evaluation.evaluator]: [0mInference done 62/72. Dataloading: 0.0303 s/iter. Inference: 15.0340 s/iter. Eval: 5.5193 s/iter. Total: 20.5842 s/iter. ETA=0:03:25
34
43
28
28
91
[32m[06/12 14:42:30 d2.evaluation.evaluator]: [0mInference done 63/72. Dataloading: 0.0298 s/iter. Inference: 15.0548 s/iter. Eval: 5.5288 s/iter. Total: 20.6140 s/iter. ETA=0:03:05
43
34
37
91
28
[32m[06/12 14:42:52 d2.evaluation.evaluator]: [0mInference done 64/72. Dataloading: 0.0315 s/iter. Inference: 15.0729 s/iter. Eval: 5.5335 s/iter. Total: 20.6385 s/iter. ETA=0:02:45
34
43
[32m[06/12 14:43:15 d2.evaluation.evaluator]: [0mInference done 65/72. Dataloading: 0.0310 s/iter. Inference: 15.0991 s/iter. Eval: 5.5460 s/iter. Total: 20.6767 s/iter. ETA=0:02:24
34
43
91
36
28
28
28
28
[32m[06/12 14:43:28 d2.evaluation.evaluator]: [0mInference done 66/72. Dataloading: 0.0305 s/iter. Inference: 15.0144 s/iter. Eval: 5.5098 s/iter. Total: 20.5553 s/iter. ETA=0:02:03
43
34
37
[32m[06/12 14:43:52 d2.evaluation.evaluator]: [0mInference done 67/72. Dataloading: 0.0310 s/iter. Inference: 15.0469 s/iter. Eval: 5.5215 s/iter. Total: 20.5999 s/iter. ETA=0:01:42
43
34
84
91
49
[32m[06/12 14:44:14 d2.evaluation.evaluator]: [0mInference done 68/72. Dataloading: 0.0305 s/iter. Inference: 15.0699 s/iter. Eval: 5.5292 s/iter. Total: 20.6301 s/iter. ETA=0:01:22
43
34
36
84
51
[32m[06/12 14:44:37 d2.evaluation.evaluator]: [0mInference done 69/72. Dataloading: 0.0301 s/iter. Inference: 15.0921 s/iter. Eval: 5.5368 s/iter. Total: 20.6595 s/iter. ETA=0:01:01
43
34
36
84
27
28
[32m[06/12 14:44:59 d2.evaluation.evaluator]: [0mInference done 70/72. Dataloading: 0.0296 s/iter. Inference: 15.1125 s/iter. Eval: 5.5425 s/iter. Total: 20.6851 s/iter. ETA=0:00:41
43
34
36
51
25
51
[32m[06/12 14:45:21 d2.evaluation.evaluator]: [0mInference done 71/72. Dataloading: 0.0292 s/iter. Inference: 15.1272 s/iter. Eval: 5.5489 s/iter. Total: 20.7058 s/iter. ETA=0:00:20
43
34
84
37
72
37
51
87
47
27
97
[32m[06/12 14:45:24 d2.evaluation.evaluator]: [0mTotal inference time: 0:22:49.704493 (20.443351 s / iter per device, on 1 devices)
[32m[06/12 14:45:24 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:16:40 (14.936361 s / iter per device, on 1 devices)
Traceback (most recent call last):
  File "/home/connecteve/intern-brendon/MM-OR/panoptic_segmentation/train_net_video.py", line 414, in <module>
    main(args)
  File "/home/connecteve/intern-brendon/MM-OR/panoptic_segmentation/train_net_video.py", line 399, in main
    res = Trainer.test(cfg, model)
  File "/home/connecteve/intern-brendon/MM-OR/panoptic_segmentation/train_net_video.py", line 305, in test
    results_i = inference_on_dataset(model, data_loader, evaluator)
  File "/home/connecteve/miniconda3/envs/mm-or/lib/python3.10/site-packages/detectron2/evaluation/evaluator.py", line 204, in inference_on_dataset
    results = evaluator.evaluate()
  File "/home/connecteve/intern-brendon/MM-OR/panoptic_segmentation/dvis_Plus/data_video/vps_eval.py", line 292, in evaluate
    with open(f'datasets/mmor_ground_truth_{dataset_split}.json', 'r') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'datasets/mmor_ground_truth_test.json'
